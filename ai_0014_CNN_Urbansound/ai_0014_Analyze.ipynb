{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded.+CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "try:\n",
    "    # MULTI GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(512, 10)\n",
    "    model = nn.DataParallel(model)  # Add this line\n",
    "    model.load_state_dict(torch.load('ResNet18_Best.pth', map_location=device))\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "\n",
    "    state_dict = torch.load('ResNet18_Best.pth', map_location=device)\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "    print(\"Model successfully loaded. + GPU\")\n",
    "except:\n",
    "    #One GPU or CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(512, 10)\n",
    "    try:\n",
    "        state_dict = torch.load('ResNet18_Best.pth', map_location=device)\n",
    "        new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "        model.load_state_dict(new_state_dict)\n",
    "        model = model.to(device)\n",
    "        model = model.eval()\n",
    "        print(\"Model successfully loaded.+CPU\")\n",
    "    except:\n",
    "        print(\"Failed to load the model. Please check the model file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "\n",
    "class MonoToColor(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(MonoToColor, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.repeat(self.num_channels, 1, 1)\n",
    "\n",
    "# Apply the same transformation as used during training\n",
    "transformation = transforms.Compose([\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=128),\n",
    "    torchaudio.transforms.AmplitudeToDB(stype='power', top_db=80),\n",
    "    MonoToColor()\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2seconds / 80% upper guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def continuous_sound_prediction(model, device, transformation, sample_rate, target_sample_rate):\n",
    "#     # Define class labels\n",
    "#     class_labels = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', \n",
    "#                     'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']\n",
    "    \n",
    "#     while True:\n",
    "#         # Record a 2 seconds mono audio at the specified sample rate\n",
    "#         duration = 2.0  # seconds\n",
    "#         recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1) \n",
    "#         sd.wait()\n",
    "\n",
    "#         # Convert to PyTorch tensor and switch channels and frames\n",
    "#         recording = torch.from_numpy(recording).float()\n",
    "#         recording = torch.transpose(recording, 0, 1)\n",
    "\n",
    "#         # Resample if necessary\n",
    "#         if sample_rate != target_sample_rate:\n",
    "#             resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
    "#             recording = resampler(recording)\n",
    "\n",
    "#         # Mix down if necessary\n",
    "#         if recording.shape[0] > 1:\n",
    "#             recording = torch.mean(recording, dim=0, keepdim=True)\n",
    "\n",
    "#         # Cut or pad if necessary\n",
    "#         if recording.shape[1] > target_sample_rate:\n",
    "#             recording = recording[:, :target_sample_rate]\n",
    "#         elif recording.shape[1] < target_sample_rate:\n",
    "#             num_missing_samples = target_sample_rate - recording.shape[1]\n",
    "#             last_dim_padding = (0, num_missing_samples)\n",
    "#             recording = nn.functional.pad(recording, last_dim_padding)\n",
    "\n",
    "#         # Apply transformation\n",
    "#         recording = transformation(recording)\n",
    "\n",
    "#         # Make the prediction\n",
    "#         model.eval()  # set model to evaluation mode\n",
    "#         with torch.no_grad():  # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "#             recording = recording.to(device)\n",
    "#             outputs = model(recording[None, ...])\n",
    "#             probabilities = F.softmax(outputs, dim=1)  # apply softmax to output\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#         # Get predicted label and its corresponding probability\n",
    "#         predicted_label = class_labels[predicted.item()]\n",
    "#         predicted_confidence = probabilities[0, predicted.item()].item()  # get the probability of the predicted class\n",
    "\n",
    "#         # Only print the output if the confidence is greater than 80%\n",
    "#         if predicted_confidence >= 0.0:\n",
    "#             print(f\"The predicted class is: {predicted_label}, with confidence: {predicted_confidence:.2%}\")\n",
    "\n",
    "#         # Sleep for 2 seconds before the next prediction\n",
    "#         #time.sleep(2.0)\n",
    "\n",
    "# # Call the continuous sound prediction function\n",
    "# continuous_sound_prediction(model, device, transformation, SAMPLE_RATE, SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def continuous_sound_prediction(model, device, transformation, sample_rate, target_sample_rate):\n",
    "#     # Define class labels\n",
    "#     class_labels = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', \n",
    "#                     'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']\n",
    "    \n",
    "#     while True:\n",
    "#         # Record a 2 seconds mono audio at the specified sample rate\n",
    "#         duration = 2.0  # seconds\n",
    "#         recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1) \n",
    "#         sd.wait()\n",
    "\n",
    "#         # Convert to PyTorch tensor and switch channels and frames\n",
    "#         recording = torch.from_numpy(recording).float()\n",
    "#         recording = torch.transpose(recording, 0, 1)\n",
    "\n",
    "#         # Resample if necessary\n",
    "#         if sample_rate != target_sample_rate:\n",
    "#             resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
    "#             recording = resampler(recording)\n",
    "\n",
    "#         # Mix down if necessary\n",
    "#         if recording.shape[0] > 1:\n",
    "#             recording = torch.mean(recording, dim=0, keepdim=True)\n",
    "\n",
    "#         # Cut or pad if necessary\n",
    "#         if recording.shape[1] > target_sample_rate:\n",
    "#             recording = recording[:, :target_sample_rate]\n",
    "#         elif recording.shape[1] < target_sample_rate:\n",
    "#             num_missing_samples = target_sample_rate - recording.shape[1]\n",
    "#             last_dim_padding = (0, num_missing_samples)\n",
    "#             recording = nn.functional.pad(recording, last_dim_padding)\n",
    "\n",
    "#         # Apply transformation\n",
    "#         recording = transformation(recording)\n",
    "\n",
    "#         # Make the prediction\n",
    "#         model.eval()  # set model to evaluation mode\n",
    "#         with torch.no_grad():  # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "#             recording = recording.to(device)\n",
    "#             outputs = model(recording[None, ...])\n",
    "#             probabilities = F.softmax(outputs, dim=1)  # apply softmax to output\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#         # Get predicted label and its corresponding probability\n",
    "#         predicted_label = class_labels[predicted.item()]\n",
    "#         predicted_confidence = probabilities[0, predicted.item()].item()  # get the probability of the predicted class\n",
    "\n",
    "#         # Only print the output if the confidence is greater than 80% and the label is not in the specified list\n",
    "#         if predicted_confidence >= 0.0 and predicted_label not in ['air_conditioner', 'children_playing', 'street_music']:#THE EXCLUDED LABLES\n",
    "#             print(f\"The predicted class is: {predicted_label}, with confidence: {predicted_confidence:.2%}\")\n",
    "#         # Sleep for 2 seconds before the next prediction\n",
    "#         #time.sleep(2.0)\n",
    "\n",
    "# # Call the continuous sound prediction function\n",
    "# continuous_sound_prediction(model, device, transformation, SAMPLE_RATE, SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb6fa2c51e245dba117d7ee0ab21501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1\n",
    "\n",
    "import sounddevice as sd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import time\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "class MonoToColor(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(MonoToColor, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.repeat(self.num_channels, 1, 1)\n",
    "\n",
    "# Define transformations\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=128)\n",
    "amplitude_to_db = torchaudio.transforms.AmplitudeToDB(stype='power', top_db=80)\n",
    "mono_to_color = MonoToColor()\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', \n",
    "                'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']\n",
    "\n",
    "# Prepare a text widget to display the prediction in real-time\n",
    "text = widgets.Text()\n",
    "display(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "def continuous_sound_prediction(model, device, sample_rate, target_sample_rate):\n",
    "    while True:\n",
    "        # Record a 2 seconds mono audio at the specified sample rate\n",
    "        duration = 2.0  # seconds\n",
    "        recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1) \n",
    "        sd.wait()\n",
    "\n",
    "        # Convert to PyTorch tensor and switch channels and frames\n",
    "        recording = torch.from_numpy(recording).float()\n",
    "        recording = torch.transpose(recording, 0, 1)\n",
    "\n",
    "        # Resample if necessary\n",
    "        if sample_rate != target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
    "            recording = resampler(recording)\n",
    "\n",
    "        # Mix down if necessary\n",
    "        if recording.shape[0] > 1:\n",
    "            recording = torch.mean(recording, dim=0, keepdim=True)\n",
    "\n",
    "        # Cut or pad if necessary\n",
    "        if recording.shape[1] > target_sample_rate:\n",
    "            recording = recording[:, :target_sample_rate]\n",
    "        elif recording.shape[1] < target_sample_rate:\n",
    "            num_missing_samples = target_sample_rate - recording.shape[1]\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            recording = nn.functional.pad(recording, last_dim_padding)\n",
    "\n",
    "        # Apply transformations\n",
    "        recording = mono_to_color(amplitude_to_db(mel_spectrogram(recording)))\n",
    "\n",
    "        # Make the prediction\n",
    "        model.eval()  # set model to evaluation mode\n",
    "        with torch.no_grad():  # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "            recording = recording.to(device)\n",
    "            outputs = model(recording[None, ...])\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)  # apply softmax to output\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Get predicted label and its corresponding probability\n",
    "        predicted_label = class_labels[predicted.item()]\n",
    "        predicted_confidence = probabilities[0, predicted.item()].item()  # get the probability of the predicted class\n",
    "\n",
    "        # Only print the output if the confidence is greater than 80% and the label is not in the specified list\n",
    "        if predicted_confidence >= 0.8 and predicted_label not in ['air_conditioner', 'children_playing', 'street_music']:\n",
    "            text.value = f\"The predicted class is: {predicted_label}, with confidence: {predicted_confidence:.2%}\"\n",
    "\n",
    "        # Sleep for 2 seconds before the next prediction\n",
    "        time.sleep(2.0)\n",
    "\n",
    "# Call the continuous sound prediction function\n",
    "continuous_sound_prediction(model, device, SAMPLE_RATE, SAMPLE_RATE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
