{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seoul 따릉이 user prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = np.genfromtxt(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/@CONTEST/ct_dacon_0001_따릉이/train.csv\",delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan at 0\n",
      "nan at 15\n",
      "nan at 19\n",
      "nan at 34\n",
      "nan at 45\n",
      "nan at 47\n",
      "nan at 85\n",
      "nan at 101\n",
      "nan at 123\n",
      "nan at 130\n",
      "nan at 141\n",
      "nan at 143\n",
      "nan at 148\n",
      "nan at 159\n",
      "nan at 170\n",
      "nan at 177\n",
      "nan at 193\n",
      "nan at 223\n",
      "nan at 235\n",
      "nan at 237\n",
      "nan at 245\n",
      "nan at 261\n",
      "nan at 266\n",
      "nan at 274\n",
      "nan at 290\n",
      "nan at 318\n",
      "nan at 325\n",
      "nan at 332\n",
      "nan at 345\n",
      "nan at 357\n",
      "nan at 377\n",
      "nan at 423\n",
      "nan at 430\n",
      "nan at 452\n",
      "nan at 464\n",
      "nan at 467\n",
      "nan at 473\n",
      "nan at 480\n",
      "nan at 490\n",
      "nan at 508\n",
      "nan at 533\n",
      "nan at 538\n",
      "nan at 555\n",
      "nan at 567\n",
      "nan at 577\n",
      "nan at 580\n",
      "nan at 590\n",
      "nan at 596\n",
      "nan at 598\n",
      "nan at 608\n",
      "nan at 624\n",
      "nan at 625\n",
      "nan at 632\n",
      "nan at 634\n",
      "nan at 646\n",
      "nan at 650\n",
      "nan at 661\n",
      "nan at 673\n",
      "nan at 681\n",
      "nan at 687\n",
      "nan at 699\n",
      "nan at 709\n",
      "nan at 729\n",
      "nan at 746\n",
      "nan at 752\n",
      "nan at 754\n",
      "nan at 764\n",
      "nan at 779\n",
      "nan at 781\n",
      "nan at 785\n",
      "nan at 792\n",
      "nan at 797\n",
      "nan at 812\n",
      "nan at 821\n",
      "nan at 856\n",
      "nan at 862\n",
      "nan at 866\n",
      "nan at 869\n",
      "nan at 877\n",
      "nan at 885\n",
      "nan at 898\n",
      "nan at 911\n",
      "nan at 924\n",
      "nan at 933\n",
      "nan at 935\n",
      "nan at 938\n",
      "nan at 949\n",
      "nan at 954\n",
      "nan at 958\n",
      "nan at 971\n",
      "nan at 1025\n",
      "nan at 1036\n",
      "nan at 1051\n",
      "nan at 1054\n",
      "nan at 1057\n",
      "nan at 1071\n",
      "nan at 1091\n",
      "nan at 1101\n",
      "nan at 1108\n",
      "nan at 1121\n",
      "nan at 1139\n",
      "nan at 1143\n",
      "nan at 1155\n",
      "nan at 1157\n",
      "nan at 1164\n",
      "nan at 1166\n",
      "nan at 1169\n",
      "nan at 1174\n",
      "nan at 1182\n",
      "nan at 1187\n",
      "nan at 1212\n",
      "nan at 1219\n",
      "nan at 1222\n",
      "nan at 1223\n",
      "nan at 1227\n",
      "nan at 1230\n",
      "nan at 1232\n",
      "nan at 1265\n",
      "nan at 1274\n",
      "nan at 1279\n",
      "nan at 1284\n",
      "nan at 1302\n",
      "nan at 1305\n",
      "nan at 1317\n",
      "nan at 1323\n",
      "nan at 1330\n",
      "nan at 1339\n",
      "nan at 1362\n",
      "nan at 1379\n",
      "nan at 1392\n",
      "nan at 1399\n",
      "nan at 1411\n"
     ]
    }
   ],
   "source": [
    "#making list with no nan\n",
    "data_nonan = []\n",
    "\n",
    "for row in range(len(data)):\n",
    "  flag = 0\n",
    "  for col in range(11):\n",
    "    if (np.isnan(data[row][col])) == True:\n",
    "      print(\"nan at %d\"%row)\n",
    "      flag = 1\n",
    "      break\n",
    "  if flag == 0:\n",
    "    data_nonan.append(data[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(data_nonan)):#recheck\n",
    "  for col in range(11):\n",
    "    if (np.isnan(data_nonan[row][col])) == True:\n",
    "      print(\"nan at %d\"%row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nonan = np.array(data_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = np.array(data_nonan[1:700,1:-1]) #get 999 data leaving about 500 data left. that 500 data will be used as test data. in col we drop 1 == id and -1 count\n",
    "y_train_list = np.array(data_nonan[1:700,-1:])\n",
    "\n",
    "x_atest_list = np.array(data_nonan[700:,1:-1])\n",
    "y_atest_list = np.array(data_nonan[700:,-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.FloatTensor(x_train_list).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train_list).to(device)\n",
    "x_atest_tensor = torch.FloatTensor(x_atest_list).to(device)\n",
    "y_atest_tensor = torch.FloatTensor(y_atest_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_atest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_atest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 1000\n",
    "dp = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:15<00:00, 64.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2777.6279296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#lr_list = [10,1,1e-1,1e-2,1e-3,1e-5,1e-7]\n",
    "lr_list = [1e-3]\n",
    "for LR in lr_list:\n",
    "  print(LR)\n",
    "  l1 = torch.nn.Linear(9,500)\n",
    "  l2 = torch.nn.Linear(500,500)\n",
    "  l3 = torch.nn.Linear(500,500)\n",
    "  l4 = torch.nn.Linear(500,1)\n",
    "  \n",
    "  torch.nn.init.xavier_normal_(l1.weight)\n",
    "  torch.nn.init.xavier_normal_(l2.weight)\n",
    "  torch.nn.init.xavier_normal_(l3.weight)\n",
    "  torch.nn.init.xavier_normal_(l4.weight)\n",
    "  \n",
    "  relu = torch.nn.ReLU()\n",
    "  loss = torch.nn.MSELoss()\n",
    "  drop = torch.nn.Dropout(p = dp)\n",
    "  \n",
    "  model = torch.nn.Sequential(l1,relu,drop,\n",
    "                              l2,relu,drop,\n",
    "                              l3,relu,drop,\n",
    "                              l4).to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters(),lr=LR)\n",
    "  \n",
    "  model.train()\n",
    "  from tqdm import tqdm\n",
    "  for epoch in tqdm(range(nb_epoch+1)):\n",
    "    hypothesis = model(x_train_tensor)\n",
    "    cost = loss(y_train_tensor,hypothesis)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    #if epoch % 200 == 0:\n",
    "  print(cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-6.4595, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "model.eval()#you need this if you are using dropout\n",
    "\n",
    "hypothesis = model(x_atest_tensor)\n",
    "diff = hypothesis - y_atest_tensor\n",
    "print(diff.sum()/len(x_atest_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = np.genfromtxt(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/@CONTEST/ct_dacon_0001_따릉이/test.csv\",delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "#making list with no nan\n",
    "data_nonan = []\n",
    "#put 1 in nan\n",
    "for row in range(len(submit_data)):\n",
    "  for col in range(10):\n",
    "    if (np.isnan(submit_data[row][col])) == True:\n",
    "        submit_data[row][col] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 1.000e+00, 1.000e+00, ..., 1.000e+00, 1.000e+00,\n",
       "        1.000e+00],\n",
       "       [0.000e+00, 7.000e+00, 2.070e+01, ..., 4.100e-02, 4.400e+01,\n",
       "        2.700e+01],\n",
       "       [1.000e+00, 1.700e+01, 3.000e+01, ..., 6.100e-02, 4.900e+01,\n",
       "        3.600e+01],\n",
       "       ...,\n",
       "       [2.165e+03, 9.000e+00, 2.330e+01, ..., 2.000e-02, 1.700e+01,\n",
       "        1.500e+01],\n",
       "       [2.166e+03, 1.600e+01, 2.700e+01, ..., 3.200e-02, 4.000e+01,\n",
       "        2.600e+01],\n",
       "       [2.177e+03, 8.000e+00, 2.230e+01, ..., 7.000e-03, 3.000e+01,\n",
       "        2.400e+01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(submit_data)):#recheck\n",
    "  for col in range(len(submit_data[0])):\n",
    "    if (np.isnan(submit_data[row][col])) == True:\n",
    "      print(\"nan at %d\"%row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = np.array(submit_data[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data_tensor = torch.Tensor(submit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = model(submit_data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 2]\n"
     ]
    }
   ],
   "source": [
    "submit_data = np.genfromtxt(\"C:/Users/OWO/Documents/AA_CODE/@Projects/@temp/4/test.csv\",delimiter=',')\n",
    "sub = []\n",
    "\n",
    "for row in range(len(hypothesis)-1):\n",
    "  temp = [submit_data[row+1][0],int(hypothesis.tolist()[row][0])]\n",
    "  sub.append(temp)\n",
    "  \n",
    "\n",
    "\n",
    "# Insert the headers as the first row of the data array\n",
    "\n",
    "\n",
    "print(sub[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.savetxt('C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/@CONTEST/ct_dacon_0001_따릉이/submission_temp.csv',sub,delimiter=\",\",fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
