{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seoul 따릉이 user prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### link\n",
    "\n",
    "https://dacon.io/competitions/open/235576/overview/description\n",
    "\n",
    "last update :  2023/01/28 0003i  \n",
    "rank : 1465  \n",
    "points : 121.29409  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = np.genfromtxt(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/@CONTEST/ct_dacon_0001_따릉이/train.csv\",delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making list with no nan\n",
    "data_nonan = []\n",
    "\n",
    "for row in range(len(data)):\n",
    "  flag = 0\n",
    "  for col in range(11):\n",
    "    if (np.isnan(data[row][col])) == True:\n",
    "      flag = 1\n",
    "      break\n",
    "  if flag == 0:\n",
    "    data_nonan.append(data[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(data_nonan)):#recheck\n",
    "  for col in range(11):\n",
    "    if (np.isnan(data_nonan[row][col])) == True:\n",
    "      print(\"nan at %d\"%row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nonan = np.array(data_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = np.array(data_nonan[1:700,1:-1]) #get 999 data leaving about 500 data left. that 500 data will be used as test data. in col we drop 1 == id and -1 count\n",
    "y_train_list = np.array(data_nonan[1:700,-1:])\n",
    "\n",
    "x_atest_list = np.array(data_nonan[700:,1:-1])\n",
    "y_atest_list = np.array(data_nonan[700:,-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.FloatTensor(x_train_list).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train_list).to(device)\n",
    "x_atest_tensor = torch.FloatTensor(x_atest_list).to(device)\n",
    "y_atest_tensor = torch.FloatTensor(y_atest_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_atest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_atest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 1000\n",
    "dp = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1001/1001 [00:15<00:00, 64.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2777.6279296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#lr_list = [10,1,1e-1,1e-2,1e-3,1e-5,1e-7]\n",
    "lr_list = [1e-3]\n",
    "for LR in lr_list:\n",
    "  print(LR)\n",
    "  l1 = torch.nn.Linear(9,500)\n",
    "  l2 = torch.nn.Linear(500,500)\n",
    "  l3 = torch.nn.Linear(500,500)\n",
    "  l4 = torch.nn.Linear(500,1)\n",
    "  \n",
    "  torch.nn.init.xavier_normal_(l1.weight)\n",
    "  torch.nn.init.xavier_normal_(l2.weight)\n",
    "  torch.nn.init.xavier_normal_(l3.weight)\n",
    "  torch.nn.init.xavier_normal_(l4.weight)\n",
    "  \n",
    "  relu = torch.nn.ReLU()\n",
    "  loss = torch.nn.MSELoss()\n",
    "  drop = torch.nn.Dropout(p = dp)\n",
    "  \n",
    "  model = torch.nn.Sequential(l1,relu,drop,\n",
    "                              l2,relu,drop,\n",
    "                              l3,relu,drop,\n",
    "                              l4).to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters(),lr=LR)\n",
    "  \n",
    "  model.train()\n",
    "  from tqdm import tqdm\n",
    "  for epoch in tqdm(range(nb_epoch+1)):\n",
    "    hypothesis = model(x_train_tensor)\n",
    "    cost = loss(y_train_tensor,hypothesis)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    #if epoch % 200 == 0:\n",
    "  print(cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-6.4595, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "model.eval()#you need this if you are using dropout\n",
    "\n",
    "hypothesis = model(x_atest_tensor)\n",
    "diff = hypothesis - y_atest_tensor\n",
    "print(diff.sum()/len(x_atest_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = np.genfromtxt(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/@CONTEST/ct_dacon_0001_따릉이/test.csv\",delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "#making list with no nan\n",
    "data_nonan = []\n",
    "#put 1 in nan\n",
    "for row in range(len(submit_data)):\n",
    "  for col in range(10):\n",
    "    if (np.isnan(submit_data[row][col])) == True:\n",
    "        submit_data[row][col] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 1.000e+00, 1.000e+00, ..., 1.000e+00, 1.000e+00,\n",
       "        1.000e+00],\n",
       "       [0.000e+00, 7.000e+00, 2.070e+01, ..., 4.100e-02, 4.400e+01,\n",
       "        2.700e+01],\n",
       "       [1.000e+00, 1.700e+01, 3.000e+01, ..., 6.100e-02, 4.900e+01,\n",
       "        3.600e+01],\n",
       "       ...,\n",
       "       [2.165e+03, 9.000e+00, 2.330e+01, ..., 2.000e-02, 1.700e+01,\n",
       "        1.500e+01],\n",
       "       [2.166e+03, 1.600e+01, 2.700e+01, ..., 3.200e-02, 4.000e+01,\n",
       "        2.600e+01],\n",
       "       [2.177e+03, 8.000e+00, 2.230e+01, ..., 7.000e-03, 3.000e+01,\n",
       "        2.400e+01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(submit_data)):#recheck\n",
    "  for col in range(len(submit_data[0])):\n",
    "    if (np.isnan(submit_data[row][col])) == True:\n",
    "      print(\"nan at %d\"%row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = np.array(submit_data[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data_tensor = torch.Tensor(submit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = model(submit_data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 2]\n"
     ]
    }
   ],
   "source": [
    "submit_data = np.genfromtxt(\"C:/Users/OWO/Documents/AA_CODE/@Projects/@temp/4/test.csv\",delimiter=',')\n",
    "sub = []\n",
    "\n",
    "for row in range(len(hypothesis)-1):\n",
    "  temp = [submit_data[row+1][0],int(hypothesis.tolist()[row][0])]\n",
    "  sub.append(temp)\n",
    "  \n",
    "\n",
    "\n",
    "# Insert the headers as the first row of the data array\n",
    "\n",
    "\n",
    "print(sub[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.savetxt('C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/@CONTEST/ct_dacon_0001_따릉이/submission_temp.csv',sub,delimiter=\",\",fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
