{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## car price tracker\n",
    "2023/01/14\n",
    "12:23\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data count : 17000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "f = open(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/ai_0002_lr_car price track/train_data.csv\")\n",
    "read = csv.reader(f)\n",
    "\n",
    "#getting data from the csv file\n",
    "data = []\n",
    "for a in read:\n",
    "  data.append(a)\n",
    "  \n",
    "#print(data)\n",
    "x_train  = data[:-4][1:]\n",
    "y_train  = data[:][-1]\n",
    "#print(x_train)\n",
    "\n",
    "#deleting the first row because thats the legend\n",
    "del data[0]\n",
    "\n",
    "\n",
    "car_year_test = []\n",
    "car_trans_test = []#transmisstion 1 == manual //  3 ==  dual clutch // \n",
    "car_milege = []\n",
    "car_fueltype =[]# 4 == Petrol // 0 == premium gasoline // 2 == gasoline \n",
    "car_tax = []\n",
    "car_mpg = []# mile per gallon\n",
    "car_enginesize = []\n",
    "car_price = []\n",
    "\n",
    "\n",
    "\n",
    "templist = []\n",
    "\n",
    "#print(data)\n",
    "\n",
    "for count in range(0,17000):\n",
    "  \n",
    "  templist.append(float(data[count][3]))\n",
    "  car_year_test.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][4]))\n",
    "  car_trans_test.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][5]))\n",
    "  car_milege.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][6]))\n",
    "  car_fueltype.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][7]))\n",
    "  car_tax.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][8]))\n",
    "  car_mpg.append(templist)\n",
    "  templist = []  \n",
    "  templist.append(float(data[count][9]))\n",
    "  car_enginesize.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][10]))\n",
    "  car_price.append(templist)\n",
    "  templist = []   \n",
    "  \n",
    "\n",
    "f.close()\n",
    "#print(pricelist)\n",
    "print(\"total data count : \"+str(len(car_price)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cant use gpu , activating cpu\n"
     ]
    }
   ],
   "source": [
    "##Hardwere\n",
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "  device = 'cuda'\n",
    "  templist = [1,2,3]\n",
    "  templist = torch.FloatTensor(templist).to(device)\n",
    "  print(\"Cude torch working : \",end=\"\")\n",
    "  print(templist.is_cuda)\n",
    "  print(\"current device no. : \",end=\"\")\n",
    "  print(torch.cuda.current_device())\n",
    "  print(\"GPU device count : \",end=\"\")\n",
    "  print(torch.cuda.device_count())\n",
    "  print(\"GPU name : \",end=\"\")\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print(\"device : \",device)\n",
    "else:\n",
    "  print(\"cant use gpu , activating cpu\")\n",
    "  device = 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Method no.1\n",
    "\n",
    "Matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Status Not good, Activating CPU calculation\n",
      "learing rate : 1.00e+00 COST : 16824.837891\n",
      "W : tensor([[2.0169e+03],\n",
      "        [1.1870e+00],\n",
      "        [2.3814e+04],\n",
      "        [2.2851e+00],\n",
      "        [1.1873e+02],\n",
      "        [5.6451e+01],\n",
      "        [1.6721e+00]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-02 COST : 63126.582031\n",
      "W : tensor([[2.4853e+01],\n",
      "        [1.8357e-02],\n",
      "        [2.3579e+02],\n",
      "        [1.1579e-02],\n",
      "        [1.4585e+00],\n",
      "        [6.3548e-01],\n",
      "        [3.4688e-02]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-03 COST : 156055.796875\n",
      "W : tensor([[ 1.3016e+01],\n",
      "        [ 2.4452e-02],\n",
      "        [ 1.7019e+01],\n",
      "        [-1.2022e-02],\n",
      "        [ 9.5239e-01],\n",
      "        [ 1.4236e-01],\n",
      "        [ 3.2636e-02]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-04 COST : 27635.173828\n",
      "W : tensor([[ 1.1740e+01],\n",
      "        [ 1.4321e-02],\n",
      "        [ 8.9641e-01],\n",
      "        [-3.5021e-03],\n",
      "        [ 9.8437e-01],\n",
      "        [ 1.7430e-01],\n",
      "        [ 2.0417e-02]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-05 COST : 6545.707031\n",
      "W : tensor([[ 7.3289e+00],\n",
      "        [ 5.5439e-03],\n",
      "        [-6.8843e-02],\n",
      "        [ 5.5422e-03],\n",
      "        [ 6.2705e-01],\n",
      "        [ 1.7811e-01],\n",
      "        [ 7.9711e-03]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-06 COST : 11480.573242\n",
      "W : tensor([[1.1075e+00],\n",
      "        [7.4946e-04],\n",
      "        [2.6721e-01],\n",
      "        [1.3722e-03],\n",
      "        [8.2052e-02],\n",
      "        [2.9039e-02],\n",
      "        [9.6414e-04]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-07 COST : 12559.634766\n",
      "W : tensor([[1.2577e-01],\n",
      "        [8.2377e-05],\n",
      "        [3.2340e-01],\n",
      "        [1.5433e-04],\n",
      "        [8.7922e-03],\n",
      "        [3.3646e-03],\n",
      "        [1.0746e-04]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-08 COST : 13474.670898\n",
      "W : tensor([[1.8604e-02],\n",
      "        [1.1172e-05],\n",
      "        [1.7777e-01],\n",
      "        [2.1331e-05],\n",
      "        [1.1122e-03],\n",
      "        [5.1992e-04],\n",
      "        [1.5445e-05]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-09 COST : 16261.331055\n",
      "W : tensor([[2.0161e-03],\n",
      "        [1.1870e-06],\n",
      "        [2.3675e-02],\n",
      "        [2.2834e-06],\n",
      "        [1.1855e-04],\n",
      "        [5.6445e-05],\n",
      "        [1.6713e-06]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-10 COST : 16767.716797\n",
      "W : tensor([[2.0189e-04],\n",
      "        [1.1882e-07],\n",
      "        [2.3838e-03],\n",
      "        [2.2874e-07],\n",
      "        [1.1885e-05],\n",
      "        [5.6508e-06],\n",
      "        [1.6738e-07]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-11 COST : 16819.125000\n",
      "W : tensor([[2.0189e-05],\n",
      "        [1.1882e-08],\n",
      "        [2.3838e-04],\n",
      "        [2.2874e-08],\n",
      "        [1.1885e-06],\n",
      "        [5.6508e-07],\n",
      "        [1.6738e-08]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-12 COST : 16824.265625\n",
      "W : tensor([[2.0189e-06],\n",
      "        [1.1882e-09],\n",
      "        [2.3838e-05],\n",
      "        [2.2874e-09],\n",
      "        [1.1885e-07],\n",
      "        [5.6508e-08],\n",
      "        [1.6738e-09]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-13 COST : 16824.781250\n",
      "W : tensor([[2.0190e-07],\n",
      "        [1.1882e-10],\n",
      "        [2.3838e-06],\n",
      "        [2.2874e-10],\n",
      "        [1.1885e-08],\n",
      "        [5.6508e-09],\n",
      "        [1.6738e-10]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-14 COST : 16824.833984\n",
      "W : tensor([[2.0189e-08],\n",
      "        [1.1882e-11],\n",
      "        [2.3837e-07],\n",
      "        [2.2874e-11],\n",
      "        [1.1885e-09],\n",
      "        [5.6508e-10],\n",
      "        [1.6738e-11]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n",
      "learing rate : 1.00e-15 COST : 16824.837891\n",
      "W : tensor([[2.0189e-09],\n",
      "        [1.1882e-12],\n",
      "        [2.3838e-08],\n",
      "        [2.2874e-12],\n",
      "        [1.1885e-10],\n",
      "        [5.6508e-11],\n",
      "        [1.6738e-12]], requires_grad=True)\n",
      "b : tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "##Hardware\n",
    "print(\"GPU Status \",end=\"\")\n",
    "print(\"Working Well\") if torch.cuda.is_available() else print(\"Not good, Activating CPU calculation\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "\n",
    "data_torch = []\n",
    "\n",
    "car_year_test = torch.FloatTensor(car_year_test).to(device)\n",
    "car_trans_test = torch.FloatTensor(car_trans_test).to(device)\n",
    "car_milege = torch.FloatTensor(car_milege).to(device)\n",
    "car_fueltype = torch.FloatTensor(car_fueltype).to(device)\n",
    "car_tax = torch.FloatTensor(car_tax).to(device)\n",
    "car_mpg = torch.FloatTensor(car_mpg).to(device)\n",
    "car_enginesize = torch.FloatTensor(car_enginesize).to(device)\n",
    "car_price = torch.FloatTensor(car_price).to(device)\n",
    "\n",
    "data_torch = torch.cat([car_year_test,car_trans_test,car_milege,car_fueltype,car_tax,car_mpg,car_enginesize],dim = 1)\n",
    "\n",
    "lr_list = [1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8,1e-9,1e-10,1e-11,1e-12,1e-13,1e-14,1e-15]\n",
    "#lr_list = [1e-5]\n",
    "for LR in lr_list:\n",
    "  \n",
    "  W = torch.zeros([7,1],requires_grad=True, device=device)\n",
    "  b = torch.zeros(1,requires_grad=True, device=device)\n",
    "  \n",
    "  optimizer = optim.SGD( [W] , lr = LR)\n",
    "  nb_epochs = 1000\n",
    "\n",
    "  for epoch in range(nb_epochs + 1):\n",
    "    # H(x) 계산\n",
    "    # Matrix 연산!!\n",
    "    hypothesis = torch.matmul(data_torch,W) + b # or .mm or @\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = torch.mean(torch.abs(hypothesis - car_price))\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \"\"\"\n",
    "    if epoch % 100000 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))\n",
    "        print(LR)\n",
    "        print(W)\n",
    "        print(b)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "  print(\"learing rate : %.2e COST : %f\"%(LR,cost.item()))\n",
    "  print(\"W : \",end=\"\")\n",
    "  print(W)\n",
    "  print(\"b : \",end=\"\")\n",
    "  print(b)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1000000/1000000 Cost: 5920.548828\n",
    "1e-05\n",
    "tensor([[  7.3967],\n",
    "        [  1.6980],\n",
    "        [ -0.1158],\n",
    "        [ -8.0022],\n",
    "        [ 34.3764],\n",
    "        [-15.1122],\n",
    "        [  3.5023]], device='cuda:0', requires_grad=True)\n",
    "tensor([0.], device='cuda:0', requires_grad=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding optim\n",
    "\n",
    "## Result : \n",
    "learing rate : 1.00e+00 COST : 16824.837891\n",
    "W : tensor([[2.0170e+03],\n",
    "        [1.1871e+00],\n",
    "        [2.3814e+04],\n",
    "        [2.2849e+00],\n",
    "        [1.1872e+02],\n",
    "        [5.6452e+01],\n",
    "        [1.6722e+00]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-02 COST : 95406.703125\n",
    "W : tensor([[ 2.5274e+01],\n",
    "        [ 1.2596e-01],\n",
    "        [ 2.3443e+02],\n",
    "        [-1.2783e+00],\n",
    "        [-2.0781e+00],\n",
    "        [-2.2283e+00],\n",
    "        [ 1.2126e+00]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-03 COST : 192555.546875\n",
    "W : tensor([[ 13.4784],\n",
    "        [  1.4357],\n",
    "        [ 15.4722],\n",
    "        [ -2.3972],\n",
    "        [  5.1327],\n",
    "        [-17.8910],\n",
    "        [  2.1180]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-04 COST : 29200.712891\n",
    "W : tensor([[ 11.6786],\n",
    "        [  0.7139],\n",
    "        [  0.8168],\n",
    "        [ -1.8871],\n",
    "        [ 11.4326],\n",
    "        [-11.6211],\n",
    "        [  1.1623]], device='cuda:0', requires_grad=True)\n",
    "## OPTIM LR : 1e-5\n",
    "learing rate : 1.00e-05 COST : 6063.766113\n",
    "W : tensor([[ 8.2146],\n",
    "        [ 0.1875],\n",
    "        [-0.1302],\n",
    "        [-0.7425],\n",
    "        [14.9173],\n",
    "        [-2.6845],\n",
    "        [ 0.3787]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-06 COST : 6251.767578\n",
    "W : tensor([[ 8.9776],\n",
    "        [ 0.0229],\n",
    "        [-0.1392],\n",
    "        [-0.0586],\n",
    "        [ 2.3025],\n",
    "        [-0.0705],\n",
    "        [ 0.0430]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-07 COST : 6546.291016\n",
    "W : tensor([[ 7.3240e+00],\n",
    "        [ 5.5396e-03],\n",
    "        [-6.8594e-02],\n",
    "        [ 5.5401e-03],\n",
    "        [ 6.2660e-01],\n",
    "        [ 1.7800e-01],\n",
    "        [ 7.9652e-03]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-08 COST : 11479.930664\n",
    "W : tensor([[1.1070e+00],\n",
    "        [7.4917e-04],\n",
    "        [2.6725e-01],\n",
    "        [1.3711e-03],\n",
    "        [8.1947e-02],\n",
    "        [2.9012e-02],\n",
    "        [9.6261e-04]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-09 COST : 12559.625000\n",
    "W : tensor([[1.2567e-01],\n",
    "        [8.2345e-05],\n",
    "        [3.2335e-01],\n",
    "        [1.5415e-04],\n",
    "        [8.7875e-03],\n",
    "        [3.3620e-03],\n",
    "        [1.0737e-04]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-10 COST : 13475.258789\n",
    "W : tensor([[1.8587e-02],\n",
    "        [1.1162e-05],\n",
    "        [1.7761e-01],\n",
    "        [2.1309e-05],\n",
    "        [1.1109e-03],\n",
    "        [5.1942e-04],\n",
    "        [1.5431e-05]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-11 COST : 16261.408203\n",
    "W : tensor([[2.0146e-03],\n",
    "        [1.1861e-06],\n",
    "        [2.3649e-02],\n",
    "        [2.2816e-06],\n",
    "        [1.1842e-04],\n",
    "        [5.6409e-05],\n",
    "        [1.6697e-06]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-12 COST : 16767.703125\n",
    "W : tensor([[2.0186e-04],\n",
    "        [1.1867e-07],\n",
    "        [2.3821e-03],\n",
    "        [2.2871e-07],\n",
    "        [1.1886e-05],\n",
    "        [5.6418e-06],\n",
    "        [1.6728e-07]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-13 COST : 16819.121094\n",
    "W : tensor([[2.0187e-05],\n",
    "        [1.1879e-08],\n",
    "        [2.3835e-04],\n",
    "        [2.2868e-08],\n",
    "        [1.1867e-06],\n",
    "        [5.6459e-07],\n",
    "        [1.6713e-08]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-14 COST : 16824.267578\n",
    "W : tensor([[2.0154e-06],\n",
    "        [1.1877e-09],\n",
    "        [2.3826e-05],\n",
    "        [2.2866e-09],\n",
    "        [1.1867e-07],\n",
    "        [5.6483e-08],\n",
    "        [1.6736e-09]], device='cuda:0', requires_grad=True)\n",
    "learing rate : 1.00e-15 COST : 16824.781250\n",
    "W : tensor([[2.0178e-07],\n",
    "        [1.1868e-10],\n",
    "        [2.3806e-06],\n",
    "        [2.2870e-10],\n",
    "        [1.1879e-08],\n",
    "        [5.6409e-09],\n",
    "        [1.6702e-10]], device='cuda:0', requires_grad=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Method 2\n",
    "\n",
    "its the same thing (in theory) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR = 1.00e-03 Epoch : 0 w1 : 0.5 w2 : 1.0 w3 : -17.7 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 1.00e-03 Epoch : 1000 w1 : 11.6 w2 : 1.0 w3 : -9.8 w4 : 1.0 w5 : 1.8 w6 : 1.1 w7 : 1.0 b : 1.0 Cost : 345648\n",
      "LR = 1.00e-04 Epoch : 0 w1 : 1.0 w2 : 1.0 w3 : -0.9 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 1.00e-04 Epoch : 1000 w1 : 11.5 w2 : 1.0 w3 : -1.4 w4 : 1.0 w5 : 1.9 w6 : 1.1 w7 : 1.0 b : 1.0 Cost : 30394\n",
      "LR = 1.00e-05 Epoch : 0 w1 : 1.0 w2 : 1.0 w3 : 0.8 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 1.00e-05 Epoch : 1000 w1 : 7.5 w2 : 1.0 w3 : -0.1 w4 : 1.0 w5 : 1.6 w6 : 1.2 w7 : 1.0 b : 1.0 Cost : 6455\n",
      "LR = 1.00e-06 Epoch : 0 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 1.00e-06 Epoch : 1000 w1 : 2.0 w2 : 1.0 w3 : 0.2 w4 : 1.0 w5 : 1.1 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 10406\n",
      "LR = 5.00e-07 Epoch : 0 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 5.00e-07 Epoch : 1000 w1 : 1.5 w2 : 1.0 w3 : 0.2 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 10967\n",
      "LR = 2.00e-08 Epoch : 0 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 2.00e-08 Epoch : 1000 w1 : 1.0 w2 : 1.0 w3 : 0.7 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 15077\n",
      "LR = 1.00e-09 Epoch : 0 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 1.00e-09 Epoch : 1000 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20550\n",
      "LR = 1.00e-10 Epoch : 0 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 1.00e-10 Epoch : 1000 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20864\n",
      "LR = 1.00e-11 Epoch : 0 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 1.00e-11 Epoch : 1000 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20895\n",
      "LR = 1.00e-12 Epoch : 0 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 1.00e-12 Epoch : 1000 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n",
      "LR = 1.00e-12 Epoch : 1000 w1 : 1.0 w2 : 1.0 w3 : 1.0 w4 : 1.0 w5 : 1.0 w6 : 1.0 w7 : 1.0 b : 1.0 Cost : 20898\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "car_year_test = torch.FloatTensor(car_year_test)\n",
    "car_trans_test = torch.FloatTensor(car_trans_test)\n",
    "car_milege = torch.FloatTensor(car_milege)\n",
    "car_fueltype = torch.FloatTensor(car_fueltype)\n",
    "car_tax = torch.FloatTensor(car_tax)\n",
    "car_mpg = torch.FloatTensor(car_mpg)\n",
    "car_enginesize = torch.FloatTensor(car_enginesize)\n",
    "car_price = torch.FloatTensor(car_price)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr_list = [1e-3,1e-4,1e-5,1e-6,5e-7,2e-8,1e-9,1e-10,1e-11,1e-12]\n",
    "#lr_list = [9.7e-10]\n",
    "for LR in lr_list:\n",
    "    \n",
    "  w1 = torch.ones(1, requires_grad=True)\n",
    "  w2 = torch.ones(1,requires_grad=True)\n",
    "  w3 = torch.ones(1,requires_grad=True)\n",
    "  w4 = torch.ones(1,requires_grad=True)\n",
    "  w5 = torch.ones(1,requires_grad=True)\n",
    "  w6 = torch.ones(1,requires_grad=True)\n",
    "  w7 = torch.ones(1,requires_grad=True)#car engine\n",
    "  b  = torch.ones(1,requires_grad=True)\n",
    "\n",
    "\n",
    "  optimizer = optim.SGD([w1,w2,w3,w4,w5,w6,w7,b], lr=LR) #learning rate\n",
    "\n",
    "  nb_epochs = 1000\n",
    "\n",
    "  for epoch in range(nb_epochs + 1):\n",
    "    #hypothesis calcuation\n",
    "    hypothesis = car_year_test * w1 + car_trans_test * w2 + car_milege * w3 + car_fueltype * w4 + car_tax * w5 + car_mpg * w6 + car_enginesize * w7 + b\n",
    "    \n",
    "    #cost calculation\n",
    "    cost = torch.mean(torch.abs(hypothesis - car_price))\n",
    "    \n",
    "    #impove H(x) with cost\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%1000 == 0:\n",
    "      print(\"LR = %.2e Epoch : %d w1 : %.1f w2 : %.1f w3 : %.1f w4 : %.1f w5 : %.1f w6 : %.1f w7 : %.1f b : %.1f Cost : %.0f\"%(LR,epoch,w1.item(),w2.item(),w3.item(),w4.item(),w5.item(),w6.item(),w7.item(),b,cost.item()))\n",
    "      \n",
    "print(\"LR = %.2e Epoch : %d w1 : %.1f w2 : %.1f w3 : %.1f w4 : %.1f w5 : %.1f w6 : %.1f w7 : %.1f b : %.1f Cost : %.0f\"%(LR,nb_epochs,w1.item(),w2.item(),w3.item(),w4.item(),w5.item(),w6.item(),w7.item(),b,cost.item()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding optim\n",
    "\n",
    "my best optimized w\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Epoch 1000000/1000000 Cost: 5920.548828\n",
    "1e-05\n",
    "tensor([[  7.3967],\n",
    "        [  1.6980],\n",
    "        [ -0.1158],\n",
    "        [ -8.0022],\n",
    "        [ 34.3764],\n",
    "        [-15.1122],\n",
    "        [  3.5023]], device='cuda:0', requires_grad=True)\n",
    "tensor([0.], device='cuda:0', requires_grad=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input NEW test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data count : 17000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "f = open(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/ai_0002_lr_car price track/train_data.csv\")\n",
    "read = csv.reader(f)\n",
    "\n",
    "#getting data from the csv file\n",
    "data = []\n",
    "for a in read:\n",
    "  data.append(a)\n",
    "#deleting the first row because thats the legend\n",
    "del data[0]\n",
    "\n",
    "\n",
    "new_car_year_test = []\n",
    "new_car_trans_test = []#transmisstion\n",
    "new_car_milege = []\n",
    "new_car_fueltype =[]# 4 == Petrol // 0 == premium gasoline // 2 == gasoline \n",
    "new_car_tax = []\n",
    "new_car_mpg = []# mile per gallon\n",
    "new_car_enginesize = []\n",
    "new_car_price = []\n",
    "\n",
    "\n",
    "\n",
    "templist = []\n",
    "\n",
    "#print(data)\n",
    "\n",
    "for count in range(17000,17084):\n",
    "  \n",
    "  templist.append(float(data[count][3]))\n",
    "  new_car_year_test.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][4]))\n",
    "  new_car_trans_test.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][5]))\n",
    "  new_car_milege.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][6]))\n",
    "  new_car_fueltype.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][7]))\n",
    "  new_car_tax.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][8]))\n",
    "  new_car_mpg.append(templist)\n",
    "  templist = []  \n",
    "  templist.append(float(data[count][9]))\n",
    "  new_car_enginesize.append(templist)\n",
    "  templist = []\n",
    "  templist.append(float(data[count][10]))\n",
    "  new_car_price.append(templist)\n",
    "  templist = []   \n",
    "  \n",
    "\n",
    "f.close()\n",
    "#print(pricelist)\n",
    "print(\"total data count : \"+str(len(car_price)))\n",
    "test_count = len(car_price)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avrage diffrence : -4532\n"
     ]
    }
   ],
   "source": [
    "#LR = 1e-5 Epoch 1000000/1000000 Cost: 5920.548828\n",
    "w1 = 7.3967\n",
    "w2 = 1.698\n",
    "w3 = -0.1158\n",
    "w4 = -8.0022\n",
    "w5 = 34.3764\n",
    "w6 = -15.1122\n",
    "w7 = 3.5023\n",
    "b = 0\n",
    "\n",
    "\n",
    "cost_sum = 0\n",
    "test_count  = len(new_car_year_test)\n",
    "\n",
    "for row in range(0,test_count):\n",
    "  hypothesis = w1 * new_car_year_test[row][0] + w2 * new_car_trans_test[row][0] + w3 * new_car_milege[row][0] + w4 * new_car_fueltype[row][0] + w5 * new_car_tax[row][0] + w6 * new_car_mpg[row][0] + w7 * new_car_enginesize[row][0] + b\n",
    "  cost_sum = hypothesis - car_price[row][0] + cost_sum\n",
    "\n",
    "print(\"avrage diffrence : \",end='')\n",
    "print(\"%.0f\"%(cost_sum/test_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the End code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello this is the Car Price Predictor\n",
      "type in the data then you will recive the price by its data\n",
      " the AI is guessing it would be : $ 18937 \n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "w1 = 7.3967\n",
    "w2 = 1.698\n",
    "w3 = -0.1158\n",
    "w4 = -8.0022\n",
    "w5 = 34.3764\n",
    "w6 = -15.1122\n",
    "w7 = 3.5023\n",
    "b = 0\n",
    "\n",
    "\n",
    "print(\"hello this is the Car Price Predictor\")\n",
    "print(\"type in the data then you will recive the price by its data\")\n",
    "\n",
    "\n",
    "new_car_year = float(input(\"type in the car's production year : \"))\n",
    "\n",
    "new_car_trans = 3 #default :  auto == 3\n",
    "trans = input(\"type in the transmisstion : \\n if manual type m . if auto type a\")\n",
    "if trans == 'm':#if manual\n",
    "  new_car_trans = 1\n",
    "\n",
    "try:\n",
    "  new_car_milage = float(input(\"type in the mileage of the car : \\nif you want to type the kilometers, type in k\"))\n",
    "except:\n",
    "  new_car_milage =  0.62137119 * float(input(\"type in the kilometers of the car : \"))\n",
    "  \n",
    "new_car_fueltype = 4#default petrol\n",
    "fuletype =  input(\"type in the fuel type of the car\\n if its petrol type p, if its premium gasoline type pr , if its diesel type in  d : \")# 4 == Petrol // 0 == premium gasoline // 2 == disel \n",
    "if fuletype == 'pr':\n",
    "  new_car_fueltype = 0\n",
    "elif fuletype == 'd':\n",
    "  new_car_fueltype = 2\n",
    "  \n",
    "new_car_tax = float(input(\"input the tax of the car you pay a year (in dollors) : \"))\n",
    "new_car_mpg = float(input(\"input the miles per gallon of the car : \"))\n",
    "new_car_enginesize = float(input(\"input the car enginesize by liters\"))\n",
    "\n",
    "print(\" the AI is guessing it would be : \",end=\"\")\n",
    "print(\"$ %.0f \"%(new_car_year * w1 + new_car_trans * w2 + new_car_milage * w3 + new_car_fueltype * w4 + new_car_tax * w5 + new_car_mpg * w6 + w7 * new_car_enginesize + b)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of project\n",
    "\n",
    "update count : 1\n",
    "\n",
    "2023/01/16 1325i -----------\n",
    "\n",
    "I solved the nan probelm, the cost was getting to high and it made the cost infinite.\n",
    "So I used aboslute rather than **2\n",
    "And also I used GPU\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2023/01/15 1225i---------------------- \n",
    "well I change my way to calculate in the last moment (the ML mothod 1)\n",
    "it makes stuff much more simple. why didnt I thought of that at from the start!\n",
    "And the mytsery thing was when the LR was just fine with 1e-9, but after when I made the ML mothod 1, 1e-9 didnt work... (I didnt find out the reason yet) But I just keeped the model (the W) with the previous one (the one with lr : 1e-9)\n",
    "\n",
    "the AI performance is not that great.. as you see , at the TEST cost, it has an avrage -$1230 diffrence.\n",
    "It was a fun project thogh. I leanred a lot.\n",
    "its 2023/01/15 1225i\n",
    "I think it took about 6 hours. Half of them was research.\n",
    "\n",
    "the data source : \n",
    "https://data.kma.go.kr/climate/StatisticsDivision/selectStatisticsDivision.do?pgmNo=158\n",
    "https://www.kamis.or.kr/customer/price/retail/period.do?action=monthly&yyyy=2023&period=28&countycode=&itemcategorycode=100&itemcode=111&kindcode=&productrankcode=&convert_kg_yn=N\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dccc2083b900c7e4253a45875410f77045ddb96f227ca83eb40747880cff069"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
