{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## project Nuclear Plant status\n",
    "\n",
    "data source : \n",
    "https://dacon.io/competitions/open/235551/data\n",
    "https://www.kaggle.com/competitions/2021-ai-w6-p1/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27671\n",
      "198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor row in range(len(data_y_original)):\\n  print(data_y[row].index(max(data_y[row])))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "#numpy.set_printoptions(threshold=numpy.Inf,linewidth=numpy.Inf) #to print the numpy list set the threshold\n",
    "data_train = numpy.genfromtxt(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/ai_0006_nn_NPP/pca_train.csv\",delimiter=\",\",encoding='UTF-8')\n",
    "data_train = data_train[1:,:]\n",
    "#print(data_train)\n",
    "\n",
    "data_y = numpy.genfromtxt(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/ai_0006_nn_NPP/train_label.csv\",delimiter=\",\",encoding='UTF-8')\n",
    "\n",
    "data_y_original = data_y[1:,1:]\n",
    "\n",
    "data_y = [[0 for col in range(int(data_y_original.max())+1)] for row in range(len(data_y_original))]\n",
    "print(len(data_y))\n",
    "print(len(data_y[0]))\n",
    "#print(data_y)\n",
    "\n",
    "for row in range(len(data_y_original)):\n",
    "  data_y[row][int(data_y_original[row][0])] = 1\n",
    "  #print(int(data_y_original[row][0]))\n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "for row in range(len(data_y_original)):\n",
    "  print(data_y[row].index(max(data_y[row])))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor row in range(len(data_y_original)):\\n  print(data_y[row].index(max(data_y[row])))\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###THIS IS FOR MAC\n",
    "\"\"\"\n",
    "import numpy\n",
    "\n",
    "data_train = numpy.genfromtxt(\"/Users/cafalena/Documents/Code/Projects/ai_0006_nn_NPP/pca_train.csv\",delimiter=\",\",encoding='UTF-8')\n",
    "data_train = data_train[1:,:]\n",
    "#print(data_train)\n",
    "\n",
    "data_y = numpy.genfromtxt(\"/Users/cafalena/Documents/Code/Projects/ai_0006_nn_NPP/train_label.csv\",delimiter=\",\",encoding='UTF-8')\n",
    "\n",
    "data_y_original = data_y[1:,1:]\n",
    "\n",
    "data_y = [[0 for col in range(int(data_y_original.max())+1)] for row in range(len(data_y_original))]\n",
    "print(len(data_y))\n",
    "print(len(data_y[0]))\n",
    "#print(data_y)\n",
    "\n",
    "for row in range(len(data_y_original)):\n",
    "  data_y[row][int(data_y_original[row][0])] = 1\n",
    "  #print(int(data_y_original[row][0]))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "for row in range(len(data_y_original)):\n",
    "  print(data_y[row].index(max(data_y[row])))\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cude torch working : True\n",
      "current device no. : 0\n",
      "GPU device count : 1\n",
      "GPU name : NVIDIA GeForce GTX 1080\n",
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "##Hardwere\n",
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "  device = 'cuda'\n",
    "  templist = [1,2,3]\n",
    "  templist = torch.FloatTensor(templist).to(device)\n",
    "  print(\"Cude torch working : \",end=\"\")\n",
    "  print(templist.is_cuda)\n",
    "  print(\"current device no. : \",end=\"\")\n",
    "  print(torch.cuda.current_device())\n",
    "  print(\"GPU device count : \",end=\"\")\n",
    "  print(torch.cuda.device_count())\n",
    "  print(\"GPU name : \",end=\"\")\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print(\"device : \",device)\n",
    "elif torch.backends.mps.is_available() == True:\n",
    "  print(\"Apple device detected\\nActivating Apple Silicon GPU\")\n",
    "  device = torch.device(\"mps\")\n",
    "else:\n",
    "  print(\"cant use gpu , activating cpu\")\n",
    "  device = 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:27<00:00, 114.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in lr : 1E+02 cost : 0.007165\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "#lr_list = [100000,1000,100,10,5,3,2,1,1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8,1e-9]\n",
    "lr_list = [100]\n",
    "nb_epoch = 10000\n",
    "for LR in lr_list:\n",
    "  \n",
    "  X = torch.FloatTensor(data_train)\n",
    "  X = X.to(device)\n",
    "  Y = torch.FloatTensor(data_y)\n",
    "  Y = Y.to(device)\n",
    "\n",
    "  #print(X.shape,Y.shape)\n",
    "\n",
    "\n",
    "  layer1 = torch.nn.Linear(256,150,bias = True)\n",
    "  layer2 = torch.nn.Linear(150,150,bias = True)\n",
    "  layer3 = torch.nn.Linear(150,150,bias = True)\n",
    "  layer4 = torch.nn.Linear(150,198,bias=True)\n",
    "\n",
    "\n",
    "  sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "  model = torch.nn.Sequential(layer1,sigmoid,layer2,sigmoid,layer3,sigmoid,layer4,sigmoid)\n",
    "  model = model.to(device)\n",
    "\n",
    "  optimizer = torch.optim.SGD(model.parameters(),lr = LR)\n",
    "  #optimizer = optimizer.to(device)\n",
    "  loss = torch.nn.BCELoss()\n",
    "  loss = loss.to(device)\n",
    "  from tqdm import tqdm\n",
    "  for epoch in tqdm(range(nb_epoch)):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    cost = loss(hypothesis,Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "  print(\"in lr : %.0E cost : %f\"%(LR,cost.item()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate\n",
    "\n",
    "in lr : 1E+05 cost : 0.505050  \n",
    "in lr : 1E+03 cost : 0.467331  \n",
    "#### in lr : 1E+02 cost : 0.007864  \n",
    "in lr : 1E+01 cost : 0.028546  \n",
    "in lr : 5E+00 cost : 0.029202  \n",
    "in lr : 3E+00 cost : 0.029217  \n",
    "in lr : 2E+00 cost : 0.029222  \n",
    "in lr : 1E+00 cost : 0.029226  \n",
    "in lr : 1E-01 cost : 0.029344  \n",
    "in lr : 1E-02 cost : 0.040540  \n",
    "in lr : 1E-03 cost : 0.355505  \n",
    "in lr : 1E-04 cost : 0.665495  \n",
    "in lr : 1E-05 cost : 0.685912  \n",
    "in lr : 1E-06 cost : 0.691508  \n",
    "in lr : 1E-07 cost : 0.718929  \n",
    "in lr : 1E-08 cost : 0.704015  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.53547034801778 %\n",
      "avrage diffrence : 3.11\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "#print(hypothesis)\n",
    "#hypothesis = hypothesis.tolist()\n",
    "#for row in range(len(data_y_original)):\n",
    "  #print(torch.argmax(hypothesis[row]))\n",
    "for row in range(len(data_y_original)):\n",
    "  prediction.append([torch.argmax(hypothesis[row]).item()])\n",
    "\n",
    "#print(prediction)\n",
    "accuracy = prediction == data_y_original\n",
    "print(accuracy.sum()/len(accuracy)*100,\"%\")\n",
    "\n",
    "##\n",
    "cost = prediction - data_y_original\n",
    "print(\"avrage diffrence : %.2f\"%(cost.sum()/len(cost)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML2 (using class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:24<00:00, 117.72it/s]\n"
     ]
    }
   ],
   "source": [
    "##ML2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        drop_prob = 0.3\n",
    "        self.fc1 = nn.Linear(256, 198,bias=True)\n",
    "        self.fc2 = nn.Linear(198, 198,bias=True)\n",
    "        self.fc3 = nn.Linear(198, 198,bias=True)\n",
    "\n",
    "        self.fc4 = nn.Linear(198, 198)\n",
    "        self.relu = torch.nn.Sigmoid()\n",
    "        self.dropout = torch.nn.Dropout(p=drop_prob)\n",
    "        ## initialize weight\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_() \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "import torch.optim as optim\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "epoch=100\n",
    "net=net.to(device)\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "X = torch.FloatTensor(data_train)\n",
    "X = X.to(device)\n",
    "Y = torch.FloatTensor(data_y)\n",
    "Y = Y.to(device)\n",
    "\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    optimizer.zero_grad()\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27671/27671 [00:02<00:00, 10903.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.47764807921651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27671/27671 [00:01<00:00, 26387.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3766036644862853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##Evaluate\n",
    "from tqdm import tqdm\n",
    "## accruacy\n",
    "sum = 0\n",
    "for i in tqdm(range(len(Y))):\n",
    "  if torch.argmax(outputs[i]) == torch.argmax(Y[i]):\n",
    "    sum = sum + 1\n",
    "print(sum/len(Y)*100)\n",
    "\n",
    "## avrage cost\n",
    "sum = 0\n",
    "for i in tqdm(range(len(Y))):\n",
    "  sum = torch.argmax(outputs[i]) - torch.argmax(Y[i]) + sum\n",
    "\n",
    "print(sum.item()/len(Y))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END\n",
    "\n",
    "2023/01/23 1413i  \n",
    "-------------update  \n",
    "using class (net)  \n",
    "\n",
    "\n",
    "\n",
    "it was hard, but easy  \n",
    "I had to learn more about NN  \n",
    "2023/01/22/0200i  \n",
    "\n",
    "Im going to sleep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
