{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## project Nuclear Plant status\n",
    "\n",
    "data source : \n",
    "https://dacon.io/competitions/open/235551/data\n",
    "https://www.kaggle.com/competitions/2021-ai-w6-p1/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27671\n",
      "198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor row in range(len(data_y_original)):\\n  print(data_y[row].index(max(data_y[row])))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "#numpy.set_printoptions(threshold=numpy.Inf,linewidth=numpy.Inf)\n",
    "data_train = numpy.genfromtxt(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/ai_0006_nn_NPP/pca_train.csv\",delimiter=\",\",encoding='UTF-8')\n",
    "data_train = data_train[1:,:]\n",
    "#print(data_train)\n",
    "\n",
    "data_y = numpy.genfromtxt(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/ai_0006_nn_NPP/train_label.csv\",delimiter=\",\",encoding='UTF-8')\n",
    "\n",
    "data_y_original = data_y[1:,1:]\n",
    "\n",
    "data_y = [[0 for col in range(int(data_y_original.max())+1)] for row in range(len(data_y_original))]\n",
    "print(len(data_y))\n",
    "print(len(data_y[0]))\n",
    "#print(data_y)\n",
    "\n",
    "for row in range(len(data_y_original)):\n",
    "  data_y[row][int(data_y_original[row][0])] = 1\n",
    "  #print(int(data_y_original[row][0]))\n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "for row in range(len(data_y_original)):\n",
    "  print(data_y[row].index(max(data_y[row])))\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cude torch working : True\n",
      "current device no. : 0\n",
      "GPU device count : 1\n",
      "GPU name : NVIDIA GeForce GTX 1080\n",
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "##Hardwere\n",
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "  device = 'cuda'\n",
    "  templist = [1,2,3]\n",
    "  templist = torch.FloatTensor(templist).to(device)\n",
    "  print(\"Cude torch working : \",end=\"\")\n",
    "  print(templist.is_cuda)\n",
    "  print(\"current device no. : \",end=\"\")\n",
    "  print(torch.cuda.current_device())\n",
    "  print(\"GPU device count : \",end=\"\")\n",
    "  print(torch.cuda.device_count())\n",
    "  print(\"GPU name : \",end=\"\")\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print(\"device : \",device)\n",
    "else:\n",
    "  print(\"cant use gpu , activating cpu\")\n",
    "  device = 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in lr : 1E+02 cost : 0.007469\n",
      "tensor(19760.3418, device='cuda:0') %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "\n",
    "#lr_list = [100000,1000,100,10,5,3,2,1,1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8,1e-9]\n",
    "lr_list = [100]\n",
    "nb_epoch = 10000\n",
    "for LR in lr_list:\n",
    "  \n",
    "  X = torch.FloatTensor(data_train)\n",
    "  X = X.to(device)\n",
    "  Y = torch.FloatTensor(data_y)\n",
    "  Y = Y.to(device)\n",
    "\n",
    "  #print(X.shape,Y.shape)\n",
    "\n",
    "\n",
    "  layer1 = torch.nn.Linear(256,150,bias = True)\n",
    "  layer2 = torch.nn.Linear(150,150,bias = True)\n",
    "  layer3 = torch.nn.Linear(150,150,bias = True)\n",
    "  layer4 = torch.nn.Linear(150,198,bias=True)\n",
    "\n",
    "\n",
    "  sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "  model = torch.nn.Sequential(layer1,sigmoid,layer2,sigmoid,layer3,sigmoid,layer4,sigmoid)\n",
    "  model = model.to(device)\n",
    "\n",
    "  optimizer = torch.optim.SGD(model.parameters(),lr = LR)\n",
    "  #optimizer = optimizer.to(device)\n",
    "  loss = torch.nn.BCELoss()\n",
    "  loss = loss.to(device)\n",
    "  \n",
    "  for epoch in range(nb_epoch):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    cost = loss(hypothesis,Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "  print(\"in lr : %.0E cost : %f\"%(LR,cost.item()))\n",
    "  #print(hypothesis)\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate\n",
    "\n",
    "in lr : 1E+05 cost : 0.505050\n",
    "in lr : 1E+03 cost : 0.467331\n",
    "#### in lr : 1E+02 cost : 0.007864\n",
    "in lr : 1E+01 cost : 0.028546\n",
    "in lr : 5E+00 cost : 0.029202\n",
    "in lr : 3E+00 cost : 0.029217\n",
    "in lr : 2E+00 cost : 0.029222\n",
    "in lr : 1E+00 cost : 0.029226\n",
    "in lr : 1E-01 cost : 0.029344\n",
    "in lr : 1E-02 cost : 0.040540\n",
    "in lr : 1E-03 cost : 0.355505\n",
    "in lr : 1E-04 cost : 0.665495\n",
    "in lr : 1E-05 cost : 0.685912\n",
    "in lr : 1E-06 cost : 0.691508\n",
    "in lr : 1E-07 cost : 0.718929\n",
    "in lr : 1E-08 cost : 0.704015\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.18748870658813 %\n",
      "avrage diffrence : 2.74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prediction = []\n",
    "#print(hypothesis)\n",
    "#hypothesis = hypothesis.tolist()\n",
    "#for row in range(len(data_y_original)):\n",
    "  #print(torch.argmax(hypothesis[row]))\n",
    "for row in range(len(data_y_original)):\n",
    "  prediction.append([torch.argmax(hypothesis[row]).item()])\n",
    "\n",
    "#print(prediction)\n",
    "accuracy = prediction == data_y_original\n",
    "print(accuracy.sum()/len(accuracy)*100,\"%\")\n",
    "\n",
    "##\n",
    "\n",
    "cost = prediction - data_y_original\n",
    "print(\"avrage diffrence : %.2f\"%(cost.sum()/len(cost)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
