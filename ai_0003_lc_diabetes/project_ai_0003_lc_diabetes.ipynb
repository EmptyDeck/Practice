{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes AI Project\n",
    "\n",
    "2023/01/17\n",
    "1726i\n",
    "\n",
    "lets code\n",
    "lets get init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718\n",
      "718\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "f =  open(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/ai_0003_lc_diabetes/diabetes.csv\")\n",
    "read = csv.reader(f)\n",
    "\n",
    "#data to list\n",
    "data = []\n",
    "for row in read:\n",
    "  data.append(row)\n",
    "\n",
    "#changing str to float\n",
    "del data[0]\n",
    "for column in range(len(data)):\n",
    "  for row in range(len(data[0])):\n",
    "    data[column][row] = float(data[column][row])\n",
    "  \n",
    "\n",
    "x_train_data = torch.Tensor(np.array(data)[:718,:-1])\n",
    "y_train_data = torch.Tensor(np.array(data)[:718,-1:])\n",
    "\n",
    "\"\"\"\n",
    "print(x_train_data.tolist())\n",
    "print(\"\\n\\n\\n\")\n",
    "print(y_train_data.tolist())\n",
    "\"\"\"\n",
    "print(len(x_train_data))\n",
    "print(len(y_train_data))\n",
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34360\\3602639312.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cuda'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mtemplist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0mtemplist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cude torch working : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "##Hardwere\n",
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "  device = 'cuda'\n",
    "  templist = [1,2,3]\n",
    "  templist = torch.FloatTensor(templist).to(device)\n",
    "  print(\"Cude torch working : \",end=\"\")\n",
    "  print(templist.is_cuda)\n",
    "  print(\"current device no. : \",end=\"\")\n",
    "  print(torch.cuda.current_device())\n",
    "  print(\"GPU device count : \",end=\"\")\n",
    "  print(torch.cuda.device_count())\n",
    "  print(\"GPU name : \",end=\"\")\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print(\"device : \",device)\n",
    "else:\n",
    "  print(\"cant use gpu , activating cpu\")\n",
    "  device = 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Status Working Well\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34360\\4091129441.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#H(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mhypothesis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m#cost = -(((y_train_data * torch.log(hypothesis))) + ((1-y_train_data)*torch.log(1-hypothesis))).mean() #nan problem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "#original\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "#Hardware\n",
    "print(\"GPU Status \",end=\"\")\n",
    "print(\"Working Well\") if torch.cuda.is_available() else print(\"Not good, Activating CPU calculation\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "x_train_data = x_train_data.to(device)\n",
    "y_train_data = y_train_data.to(device)\n",
    "\n",
    "lr_list = [1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8,1e-9,1e-10,1e-11,1e-12,1e-13,1e-14,1e-15]\n",
    "#lr_list = [1e-4]\n",
    "for LR in lr_list:\n",
    "\n",
    "  W = torch.zeros([8,1],requires_grad=True,device=device)\n",
    "  b = torch.zeros(1,requires_grad=True,device=device)\n",
    "  \n",
    "  optimizer = optim.SGD([W],lr = LR)\n",
    "  nb_epochs = 1000\n",
    "  \n",
    "  for epoch in range(nb_epochs + 1):\n",
    "    #H(x)\n",
    "    hypothesis = torch.sigmoid(torch.matmul(x_train_data,W) + b)\n",
    "    \n",
    "    #cost = -(((y_train_data * torch.log(hypothesis))) + ((1-y_train_data)*torch.log(1-hypothesis))).mean() #nan problem\n",
    "    loss = torch.nn.BCELoss()\n",
    "    cost = loss(hypothesis,y_train_data)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "  \n",
    "#result\n",
    "  print(\"LR : %E cost : %f\"%(LR,cost.item()))\n",
    "  if torch.isfinite(cost):#if its not nan\n",
    "    #print(W.tolist(),b.tolist())\n",
    "    continue\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many LR and results\n",
    "LR : 1.000000E+00 cost : 34.679665\n",
    "[[-0.21866294741630554], [-11.47144889831543], [-9.999999046325684], [-2.433147668838501], [-4.73537540435791], [-3.765042304992676], [-0.04442966729402542], [-3.800835609436035]] [0.0]\n",
    "LR : 1.000000E-02 cost : 33.583466\n",
    "[[-0.01190275140106678], [-0.4854990541934967], [-0.3549695909023285], [-0.08792246133089066], [-0.10795765370130539], [-0.13763520121574402], [-0.0017595659010112286], [-0.14691713452339172]] [0.0]\n",
    "LR : 1.000000E-03 cost : 3.829255\n",
    "[[0.18605837225914001], [0.04919402301311493], [-0.09274087101221085], [0.008428694680333138], [0.009471889585256577], [-0.00817148294299841], [0.007605382241308689], [-0.010079278610646725]] [0.0]\n",
    "LR : 1.000000E-04 cost : 0.617943\n",
    "[[0.02170534059405327], [0.01177297905087471], [-0.028922397643327713], [0.0025225477293133736], [0.0007527394336648285], [-0.003837757045403123], [0.0006097102886997163], [3.9394475606968626e-05]] [0.0]\n",
    "LR : 1.000000E-05 cost : 0.628474\n",
    "[[0.0021622241474688053], [0.006678586360067129], [-0.017302708700299263], [-0.002192592713981867], [0.0011746662203222513], [-0.0029351625125855207], [4.4178523239679635e-05], [-0.0015005868626758456]] [0.0]\n",
    "LR : 1.000000E-06 cost : 0.658451\n",
    "[[0.0001167987211374566], [-0.0011965265730395913], [-0.004046783782541752], [-0.0007474390440620482], [0.0010927162365987897], [-0.0010817514266818762], [-5.018986030336237e-06], [-0.0009623144869692624]] [0.0]\n",
    "LR : 1.000000E-07 cost : 0.677100\n",
    "[[-1.1292063391010743e-05], [-0.0008060511900112033], [-0.0008097863174043596], [-0.0001841695629991591], [-0.00019214249914512038], [-0.00028909181128256023], [-3.1206125186145073e-06], [-0.00028923540958203375]] [0.0]\n",
    "LR : 1.000000E-08 cost : 0.690457\n",
    "[[-2.0572026642184937e-06], [-0.00011054467904614285], [-9.771672921488062e-05], [-2.360487269470468e-05], [-4.369836096884683e-05], [-3.6591296520782635e-05], [-4.280936423128878e-07], [-3.6910088965669274e-05]] [0.0]\n",
    "LR : 1.000000E-09 cost : 0.692861\n",
    "[[-2.175343780663752e-07], [-1.143902863987023e-05], [-9.985596989281476e-06], [-2.4278808723465772e-06], [-4.702006663137581e-06], [-3.7575730402750196e-06], [-4.430351197015625e-08], [-3.793001951635233e-06]] [0.0]\n",
    "LR : 1.000000E-10 cost : 0.693118\n",
    "[[-2.187466563441376e-08], [-1.1478526857899851e-06], [-1.0007559012592537e-06], [-2.4348076976821176e-07], [-4.7362888722091157e-07], [-3.767680709643173e-07], [-4.445699364197253e-09], [-3.803470463026315e-07]] [0.0]\n",
    "LR : 1.000000E-11 cost : 0.693144\n",
    "[[-2.188692116433799e-09], [-1.1482512718430371e-07], [-1.0009704709545986e-07], [-2.4355248484653202e-08], [-4.7397129776527436e-08], [-3.76869380147582e-08], [-4.4472434068687505e-10], [-3.804534287610295e-08]] [0.0]\n",
    "LR : 1.000000E-12 cost : 0.693147\n",
    "[[-2.1887881784810048e-10], [-1.148295858399706e-08], [-1.0009999940052694e-08], [-2.435593726701768e-09], [-4.740069226016885e-09], [-3.768767076195445e-09], [-4.447416393493775e-11], [-3.8045948613785185e-09]] [0.0]\n",
    "LR : 1.000000E-13 cost : 0.693147\n",
    "[[-2.1888066012443197e-11], [-1.1482963468978369e-09], [-1.0009900686114293e-09], [-2.4355931160791044e-10], [-4.740108860978864e-10], [-3.768808598536566e-10], [-4.447461062623281e-12], [-3.804648263106003e-10]] [0.0]\n",
    "LR : 1.000000E-14 cost : 0.693147\n",
    "[[-2.1888070782932756e-12], [-1.1482861189682225e-10], [-1.0010133000282195e-10], [-2.4355661584762878e-11], [-4.74015826590346e-11], [-3.768808529147627e-11], [-4.4474474558860166e-13], [-3.8046066297425796e-11]] [0.0]\n",
    "LR : 1.000000E-15 cost : 0.693147\n",
    "[[-2.1887863971368354e-13], [-1.1482978630461549e-11], [-1.0009888751216778e-11], [-2.4355955620392056e-12], [-4.740098938360582e-12], [-3.768785197116875e-12], [-4.4473864695138143e-14], [-3.804618946279259e-12]] [0.0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold :  0.1 accuracy :  38.0 %\n",
      "threshold :  0.2 accuracy :  42.0 %\n",
      "threshold :  0.3 accuracy :  54.0 %\n",
      "threshold :  0.4 accuracy :  64.0 %\n",
      "threshold :  0.5 accuracy :  64.0 %\n",
      "threshold :  0.6 accuracy :  62.0 %\n",
      "threshold :  0.7 accuracy :  62.0 %\n",
      "threshold :  0.8 accuracy :  62.0 %\n",
      "threshold :  0.9 accuracy :  62.0 %\n"
     ]
    }
   ],
   "source": [
    "#Getting the rest data 720~769\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "f =  open(\"C:/Users/OWO/Documents/AA_CODE/@Projects/Projects/ai_0003_lc_diabetes/diabetes.csv\")\n",
    "read = csv.reader(f)\n",
    "\n",
    "#data to list\n",
    "data = []\n",
    "for row in read:\n",
    "  data.append(row)\n",
    "\n",
    "#changing str to float\n",
    "del data[0]\n",
    "for column in range(len(data)):\n",
    "  for row in range(len(data[0])):\n",
    "    data[column][row] = float(data[column][row])\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "x_test_data = torch.Tensor(np.array(data)[718:,:-1]).to(device)\n",
    "y_test_data = torch.Tensor(np.array(data)[718:,-1:]).to(device)\n",
    "\n",
    "#print(x_test_data.tolist())\n",
    "#print(y_test_data)\n",
    "#print(len(x_test_data))\n",
    "#print(len(y_test_data))\n",
    "\n",
    "f.close()\n",
    "threshold = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for num in threshold:\n",
    "  hypothesis = torch.sigmoid(torch.matmul(x_test_data,W)+b)#.to(device)#hypothesis\n",
    "  #print(hypothesis)\n",
    "  prediction = hypothesis >= torch.FloatTensor([num]).to(device)#making it to binary // prediction will be in true or false\n",
    "  correct_prediction = (prediction.float() == y_test_data) #if it matches it will be true  .float() will turn true to 1\n",
    "  print(\"threshold : \",num,\"accuracy : \",correct_prediction.sum().item()/len(correct_prediction)*100,\"%\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End\n",
    "\n",
    "\n",
    "2023/01/18 1354i\n",
    "I am kind of disappointed that my accuracy is only 64%.\n",
    "But I learned a lot in this project.\n",
    "\n",
    "the data source : https://www.kaggle.com/code/mathchi/diagnostic-a-patient-has-diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
